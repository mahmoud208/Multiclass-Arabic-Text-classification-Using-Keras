{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fERcWHPBiCbB"
      },
      "source": [
        "import pandas\r\n",
        "import string\r\n",
        "import nltk\r\n",
        "import keras\r\n",
        "import sklearn\r\n",
        "import time\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from time import time\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from pandas import read_csv\r\n",
        "from pandas.plotting import scatter_matrix\r\n",
        "from matplotlib import pyplot\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from keras.callbacks import TensorBoard\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense , Activation , Dropout\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\r\n",
        "import keras.preprocessing.text"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuNNPu1oiIoL",
        "outputId": "be151c3b-89f3-4bd6-ed3f-5810ce10bb36"
      },
      "source": [
        "# load dataset\r\n",
        "dataframe = pandas.read_csv(\"tet.csv\", header=0)\r\n",
        "dataframe.drop_duplicates(inplace = True)\r\n",
        "data= dataframe\r\n",
        "print(dataframe.head())\r\n",
        "\r\n",
        "print(type(data['text']))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                text    class\n",
            "0  ﻿ اعتقل اندونيسي من قبل الشرطة بعد ان اثار جدل...  religon\n",
            "1  ﻿ عمان - الراي - اكد المهندس نضال الحديد امين ...      env\n",
            "2  (2) امه هي امنه بنت وهب بن عبد مناف بن زهره بن...  religon\n",
            "3  (ناسا) لتركيب نظام قياسي ضوئي شمسي طيفي لرصد ا...       ST\n",
            "4  @ 3drees: حماقي حلف بالله انه ما يستمتع الا مع...      art\n",
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Hdtqqr8iJUS",
        "outputId": "c6038603-8c63-488b-8dfe-61fb2eaf48f7"
      },
      "source": [
        "train_size = int(len(data) * .8)\r\n",
        "\r\n",
        "print(int(len(data['text'])))\r\n",
        "print(train_size)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2393\n",
            "1914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQIVT349iJY7"
      },
      "source": [
        "texts= data['text']\r\n",
        "tags = data['class']\r\n",
        "\r\n",
        "\r\n",
        "train_posts = data['text'][:train_size]\r\n",
        "train_tags = data['class'][:train_size]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "test_posts = data['text'][train_size:]\r\n",
        "test_tags =  data['class'][train_size:]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzZGt7hQiJcT"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=None,lower=False)\r\n",
        "tokenizer.fit_on_texts(texts)\r\n",
        "\r\n",
        "x_train = tokenizer.texts_to_matrix(train_posts, mode='tfidf')\r\n",
        "x_test = tokenizer.texts_to_matrix(test_posts, mode='tfidf')\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Znxc6crCiJe8",
        "outputId": "8e01d50a-fe2b-4d1c-8646-496f6b62e158"
      },
      "source": [
        "encoder = LabelEncoder()\r\n",
        "encoder.fit(tags)\r\n",
        "tagst=encoder.fit_transform(tags)\r\n",
        "\r\n",
        "num_classes = int((len(set(tagst))))\r\n",
        "print((len(set(tagst))))\r\n",
        "\r\n",
        "y_train = encoder.fit_transform(train_tags)\r\n",
        "y_test = encoder.fit_transform(test_tags)\r\n",
        "\r\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI5uRIy3iJhz"
      },
      "source": [
        "y_train= keras.utils.to_categorical(y_train,num_classes)\r\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\r\n",
        "\r\n",
        "\r\n",
        "num_labels = int(len(y_train.shape))\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "\r\n",
        "max_words=vocab_size\r\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrUaeFiziJlL"
      },
      "source": [
        "import keras.backend as K\r\n",
        "def f1_metric(y_true, y_pred):\r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\r\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\r\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\r\n",
        "    return f1_val\r\n",
        "\r\n",
        "from keras.metrics import Precision , Recall , Accuracy , TruePositives , TrueNegatives , FalsePositives , FalseNegatives\r\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT7RswjSjUj1"
      },
      "source": [
        "\r\n",
        "# Build the model\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(1024, input_shape=(max_words,)))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(num_classes))\r\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfNiv5LCjUnM"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer='adam',\r\n",
        "              metrics=['categorical_accuracy','Recall','Precision', f1_metric,'TruePositives','TrueNegatives','FalsePositives','FalseNegatives'])\r\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-3RzayTjUss",
        "outputId": "ab3952da-e6a0-48ed-c06e-0e0942a54d42"
      },
      "source": [
        "batch_size = 100\r\n",
        "epochs = 2\r\n",
        "\r\n",
        "history = model.fit(x_train, y_train,\r\n",
        "                    batch_size=batch_size,\r\n",
        "                    epochs=epochs,\r\n",
        "                    verbose=1,\r\n",
        "                    validation_split=0.1)\r\n",
        "\r\n",
        "\r\n",
        "model.save('my_model.h1')\r\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "18/18 [==============================] - 6s 276ms/step - loss: 0.9842 - categorical_accuracy: 0.6653 - recall: 0.8066 - precision: 0.3348 - f1_metric: 0.4723 - true_positives: 862.8421 - true_negatives: 3422.4737 - false_positives: 1510.1579 - false_negatives: 123.6842 - val_loss: 0.2724 - val_categorical_accuracy: 0.9167 - val_recall: 0.9740 - val_precision: 0.4022 - val_f1_metric: 0.5724 - val_true_positives: 187.0000 - val_true_negatives: 682.0000 - val_false_positives: 278.0000 - val_false_negatives: 5.0000\n",
            "Epoch 2/2\n",
            "18/18 [==============================] - 4s 231ms/step - loss: 0.0179 - categorical_accuracy: 0.9987 - recall: 0.9987 - precision: 0.6085 - f1_metric: 0.7571 - true_positives: 985.5789 - true_negatives: 4332.9474 - false_positives: 599.6842 - false_negatives: 0.9474 - val_loss: 0.1445 - val_categorical_accuracy: 0.9635 - val_recall: 0.9896 - val_precision: 0.4922 - val_f1_metric: 0.6634 - val_true_positives: 190.0000 - val_true_negatives: 764.0000 - val_false_positives: 196.0000 - val_false_negatives: 2.0000\n",
            "INFO:tensorflow:Assets written to: my_model.h1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdiaV7a5jUw0"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "# saving\r\n",
        "with open('tokenizer.pickle', 'wb') as handle:\r\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\r\n",
        "\r\n",
        "# loading\r\n",
        "with open('tokenizer.pickle', 'rb') as handle:\r\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH4-eWntjU0j",
        "outputId": "98354029-a9af-48fc-bbdc-81b945f5526d"
      },
      "source": [
        "#model = keras.models.load_model('my_model.h1')\r\n",
        "Evaluation_valus = model.evaluate(x_test,y_test,verbose=0)\r\n",
        "print(\"Loss\" , 'categorical_accuracy','Recall','Precision','f1_metric','TruePositives','TrueNegatives','FalsePositives','FalseNegatives')\r\n",
        "\r\n",
        "print(Evaluation_valus)\r\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss categorical_accuracy Recall Precision f1_metric TruePositives TrueNegatives FalsePositives FalseNegatives\n",
            "[4.277341365814209, 0.5344467759132385, 0.705636739730835, 0.2680412232875824, 0.39802804589271545, 338.0, 1472.0, 923.0, 141.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmGMv_lRkWV-",
        "outputId": "6b297943-54fd-4c93-b95b-ff3465d4855b"
      },
      "source": [
        "for x in data[\"text\"][:25]:\r\n",
        "\r\n",
        "    tokens = tokenizer.texts_to_matrix([x], mode='tfidf')\r\n",
        "\r\n",
        "    c=model.predict(np.array(tokens))\r\n",
        "    cc=model.predict_classes(tokens)\r\n",
        "    xc = encoder.inverse_transform(cc)\r\n",
        "\r\n",
        "\r\n",
        "    print(c,\"= \\t\",cc,\"\\t\",xc)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.36428607 0.24974772 0.04651052 0.2054654  0.52084166 0.993569  ]] = \t [5] \t ['religon']\n",
            "[[0.3030743  0.46091425 0.80617106 0.24373052 0.38295197 0.61700827]] = \t [2] \t ['env']\n",
            "[[0.440311   0.21136141 0.02192056 0.15663287 0.3451142  0.99925   ]] = \t [5] \t ['religon']\n",
            "[[0.9840672  0.398261   0.13495126 0.3047344  0.58162874 0.37157065]] = \t [0] \t ['ST']\n",
            "[[4.1538179e-02 9.9999940e-01 8.4075332e-04 3.2625526e-02 1.9854477e-01\n",
            "  3.7974361e-01]] = \t [1] \t ['art']\n",
            "[[1.08609855e-01 9.99999523e-01 7.72416592e-04 4.07330990e-02\n",
            "  2.29737163e-01 4.18069184e-01]] = \t [1] \t ['art']\n",
            "[[0.13954115 0.99994886 0.004195   0.09884748 0.22609967 0.27460098]] = \t [1] \t ['art']\n",
            "[[0.21486339 0.99979585 0.01276469 0.19264224 0.25429073 0.2874838 ]] = \t [1] \t ['art']\n",
            "[[3.8344234e-02 1.0000000e+00 8.5467822e-05 2.1513134e-02 1.5300035e-01\n",
            "  2.2812390e-01]] = \t [1] \t ['art']\n",
            "[[0.99999726 0.0994091  0.00100526 0.18401262 0.29807872 0.274534  ]] = \t [0] \t ['ST']\n",
            "[[2.6279879e-01 2.8432786e-02 8.2998586e-06 7.7256262e-03 1.0000000e+00\n",
            "  6.0456038e-02]] = \t [4] \t ['pol']\n",
            "[[2.7016640e-02 1.0000000e+00 1.1602005e-04 6.2102377e-03 2.1918595e-02\n",
            "  1.2767616e-01]] = \t [1] \t ['art']\n",
            "[[0.28869772 0.9986301  0.02755138 0.1694639  0.2902696  0.31085473]] = \t [1] \t ['art']\n",
            "[[7.8723669e-02 9.9999863e-01 2.9593706e-04 2.4663299e-02 3.3162779e-01\n",
            "  1.4873978e-01]] = \t [1] \t ['art']\n",
            "[[0.21043065 0.9950118  0.04849902 0.22463751 0.40657595 0.35829884]] = \t [1] \t ['art']\n",
            "[[2.0340389e-01 3.9118358e-01 7.1367621e-04 8.7024778e-02 3.7673166e-01\n",
            "  9.9999946e-01]] = \t [5] \t ['religon']\n",
            "[[0.18872115 0.23929486 0.00152498 0.15166691 0.3418454  0.99999845]] = \t [5] \t ['religon']\n",
            "[[0.26976967 0.29833287 0.01727885 0.12607178 0.85599744 0.99874544]] = \t [5] \t ['religon']\n",
            "[[0.3911057  0.2500555  0.00220478 0.174151   0.3022983  0.99999094]] = \t [5] \t ['religon']\n",
            "[[0.14486739 0.04726937 0.00514585 0.06439894 0.9999954  0.31756812]] = \t [4] \t ['pol']\n",
            "[[0.17935652 0.07597351 0.00951186 0.09053123 0.99999624 0.23727426]] = \t [4] \t ['pol']\n",
            "[[0.30996847 0.16183561 0.01425105 0.09179568 0.9995911  0.7337378 ]] = \t [4] \t ['pol']\n",
            "[[0.20512098 0.26810533 0.01291811 0.24590686 0.30029678 0.9998404 ]] = \t [5] \t ['religon']\n",
            "[[0.38781476 0.2783677  0.01137435 0.99847996 0.47682303 0.42457995]] = \t [3] \t ['fin']\n",
            "[[5.2285612e-01 1.8488961e-01 7.1486831e-04 9.9998158e-01 4.4521183e-01\n",
            "  3.0281025e-01]] = \t [3] \t ['fin']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
